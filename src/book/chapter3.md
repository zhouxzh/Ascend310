---
title: "第3讲：边缘计算基础与系统视角"
author: [周贤中]
date: 2025-09-04
subject: "Markdown"
keywords: [边缘计算, 架构, 协同, 资源管理, QoS, 缓存策略]
lang: zh-cn
---

## 章节总览
本章由“为什么→模式→数据流→资源→QoS→编排→安全与缓存→实践”九个逻辑段构成，旨在建立工程化视角：不仅能部署单模型，更能做整体系统性能、可靠性与成本的动态平衡。强调“数据流 + 控制流 + 资源流”三合一思维。

## 3.1 边缘计算价值驱动详解
1. 时延：回路 = 采集 → 编码/传输 → 云计算 → 回传 → 动作；若云往返 >100ms 则交互体验显著下降。边缘内联决策可将控制时延压缩到 20~40ms 级别（摄像头同机推理）。
2. 带宽：1080p30 原始视频 ~6–8 Mbps/流；100 路上传云成本与链路压力极高；边缘提取结构化事件再上传（<100 kbps/流）。
3. 隐私合规：原始人脸/车牌本地脱敏或仅上传特征向量，满足数据最小化原则。
4. 稳定性：弱网/离线时保持核心功能；边缘缓冲 + 延迟上报避免数据断点。
5. 成本：云侧 GPU/NPU 按时计费；大量重复计算迁移到一次购买、长期折旧的边缘硬件更经济。

## 3.2 协同模式全景与决策矩阵
| 模式 | 数据驻留 | 计算位置 | 优势 | 局限 | 适配指标门槛 |
| ---- | -------- | -------- | ---- | ---- | ------------- |
| 全云推理 | 云 | 云 GPU/NPU | 开发简单 | 带宽/时延高 | FPS不敏感, 低并发 |
| 端直传云 | 端缓存极少 | 云 | 快速迭代 | 传输不稳定 | 可靠网络 |
| 边缘本地推理 | 边 | 边 NPU | 低时延 | 本地运维 | <50ms 时延目标 |
| 云-边分层 | 边过滤, 云聚合 | 两端 | 负载平衡 | 架构复杂 | 事件/特征上云 |
| 端-边协同缓存 | 端临时缓冲 | 边 | 容错好 | 端资源有限 | 离线弹性需求 |
| 模型分片（前后部） | 端/边各一段 | 端+边 | 大模型裁剪 | 分界优化难 | 特征稳定性 |

决策流程：场景目标时延 → 网络稳定性 → 数据敏感级别 → 模型复杂度与体积 → 运维能力 → 成本预算。

## 3.3 数据生命周期深度拆解
| 阶段 | 关键动作 | 质量风险 | 监控指标 | 优化策略 |
| ---- | -------- | -------- | -------- | -------- |
| 采集 | 曝光/白平衡/帧率 | 过曝/抖动 | 帧率实际值 | 自适应参数 |
| 预处理 | Resize/Color/Normalize | 失真/色彩偏差 | 预处理耗时 | SIMD/批量化 |
| 推理 | 单/多模型 | Fallback/长尾层 | 时延分布 | 多线程/Stream |
| 后处理 | NMS/Decode | 漏检/误检 | 算子耗时 | 向量化/阈值调优 |
| 缓存 | 本地 ring buffer | OOM/过期 | 缓存命中率 | LRU/分层存储 |
| 上报 | 批量/事件 | 延迟/丢包 | 成功率/P95 | 重试/ACK |
| 清理 | 过期数据删除 | 磁盘膨胀 | 占用比 | 后台限速清理 |

清晰标注每步输入输出 Contract（格式、单位、最大尺寸）。

## 3.4 系统结构模式与演进
1. 单板单进程：最小化；适合 PoC。缺：难扩展 & 崩溃影响全局。
2. 单板多进程：采集、推理、上报、监控分离；通过本地 IPC（共享内存 / ZeroMQ）。
3. 多板协同：中央调度节点（任务分发 + 健康探测），板间心跳；支持水平扩展。
4. 异构协作：CPU 负责 Decode/I/O，NPU 执行推理，GPU (若有) 进行特征渲染或可视化。

演进触发条件：CPU 利用率>70% 长期、推理排队、单点故障影响 SLA。

## 3.5 资源画像模型化
为模型定义结构化画像：
```
{
	"model": "yolov5s",
	"input": "1x3x640x640",
	"avg_latency_ms": 28.4,
	"memory_peak_mb": 620,
	"compute_type": "conv-dense",
	"io_intensity": "medium",
	"fallback_ops": []
}
```
依据画像做编排：
- 高 I/O 密度任务与计算密集型错峰执行。
- 热点算子分组，避免同一时间窗口内全部提交导致带宽抖动。
热设计：读取温度曲线（如每 5s 采样），超过阈值 85°C 触发降频/任务降载。

## 3.6 QoS 指标与 SLO / SLA 构建
| 层 | 指标 | 目标示例 | 采集方式 | 触发动作 |
| -- | ---- | -------- | -------- | -------- |
| 用户体验 | 端到端时延 P95 | <80ms | 帧时间戳 | 降分辨率 |
| 系统性能 | 推理 FPS | ≥25 | 内部计数 | 动态并行数 |
| 稳定性 | Crash / 24h | 0 | 守护进程 | 自动重启 & 上报 |
| 资源 | 内存占用峰值 | <75% | /proc | 内存回收/分批 |
| 能耗 | 平均功耗 | <TDP*0.85 | 传感器 | 降载 |
| 质量 | 精度回归差异 | <0.5% | 回放集 | 触发模型回滚 |

SLO→内部工程指标；SLA→面向外部承诺（可只暴露子集）。

## 3.7 任务编排与背压控制机制
排队公式：Little 定律 L=λW；若摄像头输入 30FPS，系统最大稳态处理能力 25FPS，则积压速率 5FPS → 需丢帧或降采样。
策略：
1. 多级队列：RealtimeQueue(丢弃旧帧) + BatchQueue(精细分析)。
2. 背压信号：队列长度 / 等待时延阈值；触发降级（Skip N 帧 / 降分辨率）。
3. Pipeline 并行：采集→预处理→推理→后处理 各自线程池；使用无锁环形缓冲减少锁竞争。
4. 自适应速率：动态测量过去窗口平均处理时延，调整采集或提交频率。

## 3.8 缓存 / 持久化与一致性
存储分层：
| 层 | 媒介 | 用途 | 容量 | 失效策略 |
| -- | ---- | ---- | ---- | -------- |
| L0 | 内存环形缓冲 | 最近帧/特征 | 小 | 覆盖写入 |
| L1 | 本地 SSD | 临时批量 | 中 | TTL + LRU |
| L2 | 云对象存储 | 长期归档 | 大 | 生命周期策略 |

一致性需求：大多数边缘场景最终一致即可；重要事件（告警）采用幂等标识 + 重试确认。
脱敏：在写入 L1 前做图像马赛克/裁剪；特征向量单向哈希化再上传。

## 3.9 安全与隔离策略深度
1. 运行用户最小权限：专用非 root 用户 + 限制设备节点访问。
2. 文件完整性：启动时计算关键二进制 SHA256；异常记录报警。
3. 配置加密：含密钥/Token 的配置采用 KMS 或本地受限权限文件；运行解密仅在内存保留。
4. 防篡改：只读分区（根镜像），可写数据分区独立挂载。
5. 更新策略：A/B 分区或镜像双缓冲，失败自动回滚。

## 3.10 容量规划示例
假设：单模型平均 30ms 推理 + 5ms 前后处理，总 35ms/帧 → 理论最大 ~28.5 FPS。
若需要同时处理 2 路 1080p 流并保持各 ≥20 FPS：
总需求 40 FPS > 单实例 28.5 FPS → 方案：
1. 两实例并行（不同进程绑定同一 NPU 需评估调度冲突）。
2. 降分辨率 1080p→960p 降低计算 ~15%。
3. 开启 FP16/INT8（若精度可接受）。

## 3.11 故障场景演练与降级矩阵
| 故障 | 影响 | 监测信号 | 降级动作 | 恢复判定 |
| ---- | ---- | -------- | -------- | -------- |
| 高温 | 降频/性能波动 | 温度>阈值 | 降帧/关闭次要模型 | 温度回落 < 阈值-5°C |
| 网络中断 | 上报延迟 | 上报失败率高 | 本地缓存 + 限深 | 连续成功上报 N 次 |
| 内存泄漏 | OOM 风险 | 内存线性增长 | 重启推理进程 | 重启后曲线平稳 |
| 模型异常输出 | 结果失真 | 精度监测偏差 | 回滚旧版本 | 指标恢复 |

## 3.12 指标采集与可视化建议
- 统一 Metrics SDK：提供 `record_latency(name, ms)`、`gauge(name, value)`、`counter(name, inc)`。
- 本地暴露 HTTP /metrics（Prometheus 格式）或写入轻量 TSDB。
- 建议核心 Dashboard：系统概览 / 时延拓扑 / 队列深度 / 资源与温度。

## 3.13 系统设计案例（简述）
多模型（检测+分类）双流：
1. FrameDispatcher：接入摄像头帧 → 分发到推理队列（按负载自适应裁剪尺寸）。
2. DetectorWorker：批量聚合 4 帧执行，产出候选框。
3. CropService：GPU/CPU 并行裁剪，批量送入 ClassifierWorker。
4. ClassifierWorker：类别结果写入共享结果队列。
5. Uploader：事件聚合（阈值过滤）→ 签名 → 上报。
平均端到端 ~55ms，P95 ~68ms；通过丢弃过期帧保护实时性。

## 3.14 章节小结
边缘系统设计的本质是多目标优化：时延、精度、稳定、成本、安全。通过资源画像、协同模式选择、分层缓存、任务编排与降级策略形成一套可演进体系。后续章节将把单模型部署扩展到多模型与工程化落地。

## 3.15 实践任务
1. 基于你的目标场景输出一份协同模式决策表（含放弃理由）。
2. 编写数据生命周期图（ASCII 或 Mermaid）。
3. 实现一个队列背压示例：当处理时延>阈值时自动丢弃旧帧。
4. 采集 10 分钟温度与时延数据，绘制相关性（是否热导致抖动）。
5. 设计一份故障降级矩阵并评审可行性。

