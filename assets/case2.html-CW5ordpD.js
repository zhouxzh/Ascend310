import{_ as i}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,d as l,o as a}from"./app-qOQMBkXC.js";const e={};function t(h,s){return a(),n("div",null,s[0]||(s[0]=[l(`<h1 id="案例2-边缘端实时目标跟踪" tabindex="-1"><a class="header-anchor" href="#案例2-边缘端实时目标跟踪"><span>案例2：边缘端实时目标跟踪</span></a></h1><hr><h2 id="项目简介" tabindex="-1"><a class="header-anchor" href="#项目简介"><span>项目简介</span></a></h2><p>本项目展示如何在昇腾310B上部署一个高效的实时目标跟踪系统。系统能够在视频流中自动检测并持续跟踪指定目标（如人员、车辆、特定物体等），即使目标发生遮挡、形变或快速移动，也能保持稳定的跟踪效果。</p><p>该项目结合了深度学习目标检测和传统跟踪算法的优势，在保证跟踪精度的同时，实现了边缘设备上的实时推理，为安防监控、智能交通、机器人导航等应用场景提供了技术基础。</p><h2 id="内容大纲" tabindex="-1"><a class="header-anchor" href="#内容大纲"><span>内容大纲</span></a></h2><h3 id="硬件准备" tabindex="-1"><a class="header-anchor" href="#硬件准备"><span>硬件准备</span></a></h3><ul><li><strong>核心计算单元</strong>: 昇腾310B开发者套件</li><li><strong>图像采集</strong>: 高清USB摄像头或IP摄像头</li><li><strong>显示设备</strong>: HDMI显示器，用于实时查看跟踪效果</li><li><strong>存储设备</strong>: 高速SD卡或USB存储设备，用于保存跟踪视频</li><li><strong>网络设备 (可选)</strong>: 以太网连接，用于远程监控</li><li><strong>电源</strong>: 稳定的电源供应</li></ul><p><em>硬件连接示意图</em></p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>昇腾310B ── USB摄像头</span></span>
<span class="line"><span>    │</span></span>
<span class="line"><span>    ├── HDMI显示器</span></span>
<span class="line"><span>    ├── 网络连接</span></span>
<span class="line"><span>    └── 电源适配器</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="软件环境" tabindex="-1"><a class="header-anchor" href="#软件环境"><span>软件环境</span></a></h3><ul><li><strong>操作系统</strong>: Ubuntu 20.04 LTS</li><li><strong>CANN版本</strong>: 7.0.RC1 或更高</li><li><strong>Python版本</strong>: 3.8.10</li><li><strong>核心依赖库</strong>: <ul><li><code>opencv-python</code>: 图像处理和视频读取</li><li><code>numpy</code>: 数值计算</li><li><code>torch</code>: 深度学习框架</li><li><code>torchvision</code>: 计算机视觉工具</li><li><code>pillow</code>: 图像处理</li><li><code>matplotlib</code>: 数据可视化</li></ul></li></ul><p><em>环境安装脚本 (<code>setup_env.sh</code>)</em></p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">#!/bin/bash</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 更新系统</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> update</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> &amp;&amp; </span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> upgrade</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -y</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 安装Python依赖</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">pip3</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> opencv-python</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> numpy</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> torch</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> torchvision</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> pillow</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> matplotlib</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 安装CANN开发套件</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># (此处应包含具体的CANN安装步骤)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">echo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &quot;环境安装完成!&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="数据集准备" tabindex="-1"><a class="header-anchor" href="#数据集准备"><span>数据集准备</span></a></h3><ul><li><p><strong>目标检测数据集</strong>:</p><ul><li><strong>COCO数据集</strong>: 用于预训练目标检测模型</li><li><strong>自定义数据集</strong>: 根据具体应用场景收集的目标图像</li></ul></li><li><p><strong>跟踪数据集</strong>:</p><ul><li><strong>MOT Challenge</strong>: 多目标跟踪基准数据集</li><li><strong>LaSOT</strong>: 大规模单目标跟踪数据集</li><li><strong>自建跟踪序列</strong>: 针对特定场景的视频序列</li></ul></li><li><p><strong>数据预处理 (<code>preprocess_data.py</code>)</strong>:</p><ul><li>视频帧提取</li><li>目标标注格式转换</li><li>数据增强（翻转、缩放、亮度调整）</li><li>训练/验证集划分</li></ul></li></ul><h3 id="模型训练与选择" tabindex="-1"><a class="header-anchor" href="#模型训练与选择"><span>模型训练与选择</span></a></h3><ul><li><p><strong>目标检测模型</strong>:</p><ul><li><strong>YOLOv8</strong>: 最新的YOLO系列，速度和精度平衡</li><li><strong>SSD MobileNet</strong>: 轻量级检测模型，适合边缘设备</li><li><strong>RetinaNet</strong>: 单阶段检测器，处理小目标效果好</li></ul></li><li><p><strong>跟踪算法选择</strong>:</p><ul><li><strong>DeepSORT</strong>: 结合外观特征的多目标跟踪</li><li><strong>ByteTrack</strong>: 基于简单关联的高性能跟踪算法</li><li><strong>FairMOT</strong>: 端到端的检测与跟踪联合训练</li></ul></li><li><p><strong>训练流程</strong>:</p><ol><li>使用预训练检测模型作为backbone</li><li>在自定义数据集上fine-tune</li><li>集成跟踪算法</li><li>端到端优化跟踪性能</li></ol></li></ul><h3 id="模型部署" tabindex="-1"><a class="header-anchor" href="#模型部署"><span>模型部署</span></a></h3><ul><li><p><strong>模型转换流程</strong>:</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" data-title="bash" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 1. PyTorch模型转ONNX</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">python3</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> convert_to_onnx.py</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --model</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> yolov8s.pt</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --output</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> yolov8s.onnx</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 2. ONNX转昇腾.om格式</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">atc</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --model=yolov8s.onnx</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --framework=5</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --output=yolov8s</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --input_format=NCHW</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --input_shape=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;images:1,3,640,640&quot;</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> \\</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">    --soc_version=Ascend310B1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p><strong>实时跟踪主程序 (<code>tracking_app.py</code>)</strong>:</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 核心流程示例</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">. 初始化昇腾推理引擎</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">. 加载检测和跟踪模型</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">. 打开视频流</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">4</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">. 循环处理每一帧:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">   -</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> 目标检测</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">   -</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> 跟踪算法更新</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">   -</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> 绘制跟踪轨迹</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">   -</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> 显示结果</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">. 保存跟踪结果</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><h3 id="_3d打印结构件" tabindex="-1"><a class="header-anchor" href="#_3d打印结构件"><span>3D打印结构件</span></a></h3><ul><li><strong>摄像头云台 (<code>camera_gimbal.stl</code>)</strong>: <ul><li>支持水平360°、垂直±45°旋转</li><li>可配合步进电机实现自动跟踪</li></ul></li><li><strong>设备保护外壳 (<code>protective_case.stl</code>)</strong>: <ul><li>防尘防水设计</li><li>散热孔布局优化</li></ul></li><li><strong>安装支架 (<code>mounting_bracket.stl</code>)</strong>: <ul><li>适配标准三脚架接口</li><li>多角度调节机构</li></ul></li></ul><p><em>3D打印参数建议</em>:</p><ul><li><strong>材料</strong>: PETG (强度高，耐温性好)</li><li><strong>层高</strong>: 0.15mm (保证精度)</li><li><strong>填充率</strong>: 30% (强度与重量平衡)</li></ul><h3 id="用户手册" tabindex="-1"><a class="header-anchor" href="#用户手册"><span>用户手册</span></a></h3><h4 id="快速开始" tabindex="-1"><a class="header-anchor" href="#快速开始"><span>快速开始</span></a></h4><ol><li><strong>硬件连接</strong>: 按照连接图组装硬件</li><li><strong>环境配置</strong>: 运行 <code>setup_env.sh</code> 安装依赖</li><li><strong>模型下载</strong>: 下载预训练模型文件</li><li><strong>启动跟踪</strong>: <code>python3 tracking_app.py --source 0</code></li></ol><h4 id="高级配置" tabindex="-1"><a class="header-anchor" href="#高级配置"><span>高级配置</span></a></h4><ul><li><strong>跟踪参数调优</strong>: 修改 <code>config.yaml</code> 中的跟踪阈值</li><li><strong>多目标跟踪</strong>: 启用 <code>--multi-target</code> 参数</li><li><strong>结果保存</strong>: 使用 <code>--save-video</code> 保存跟踪视频</li></ul><h4 id="性能优化" tabindex="-1"><a class="header-anchor" href="#性能优化"><span>性能优化</span></a></h4><ul><li><strong>推理加速</strong>: 启用混合精度推理</li><li><strong>内存优化</strong>: 调整批处理大小</li><li><strong>延迟优化</strong>: 减少后处理步骤</li></ul><h2 id="源代码结构" tabindex="-1"><a class="header-anchor" href="#源代码结构"><span>源代码结构</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>tracking_project/</span></span>
<span class="line"><span>├── models/</span></span>
<span class="line"><span>│   ├── detection/      # 检测模型</span></span>
<span class="line"><span>│   ├── tracking/       # 跟踪算法</span></span>
<span class="line"><span>│   └── utils/         # 工具函数</span></span>
<span class="line"><span>├── data/</span></span>
<span class="line"><span>│   ├── datasets/      # 训练数据</span></span>
<span class="line"><span>│   └── pretrained/    # 预训练模型</span></span>
<span class="line"><span>├── configs/           # 配置文件</span></span>
<span class="line"><span>├── scripts/           # 训练和转换脚本</span></span>
<span class="line"><span>└── demo/             # 演示程序</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="效果演示" tabindex="-1"><a class="header-anchor" href="#效果演示"><span>效果演示</span></a></h2><ul><li><strong>单目标跟踪</strong>: 视频中展示对人员的持续跟踪</li><li><strong>多目标跟踪</strong>: 同时跟踪多个车辆或行人</li><li><strong>遮挡处理</strong>: 目标被遮挡后重新出现的跟踪恢复</li><li><strong>实时性能</strong>: FPS指标和延迟统计</li></ul>`,35)]))}const d=i(e,[["render",t],["__file","case2.html.vue"]]),o=JSON.parse('{"path":"/experiment/case2.html","title":"案例2：边缘端实时目标跟踪","lang":"zh-CN","frontmatter":{},"headers":[{"level":2,"title":"项目简介","slug":"项目简介","link":"#项目简介","children":[]},{"level":2,"title":"内容大纲","slug":"内容大纲","link":"#内容大纲","children":[{"level":3,"title":"硬件准备","slug":"硬件准备","link":"#硬件准备","children":[]},{"level":3,"title":"软件环境","slug":"软件环境","link":"#软件环境","children":[]},{"level":3,"title":"数据集准备","slug":"数据集准备","link":"#数据集准备","children":[]},{"level":3,"title":"模型训练与选择","slug":"模型训练与选择","link":"#模型训练与选择","children":[]},{"level":3,"title":"模型部署","slug":"模型部署","link":"#模型部署","children":[]},{"level":3,"title":"3D打印结构件","slug":"_3d打印结构件","link":"#_3d打印结构件","children":[]},{"level":3,"title":"用户手册","slug":"用户手册","link":"#用户手册","children":[]}]},{"level":2,"title":"源代码结构","slug":"源代码结构","link":"#源代码结构","children":[]},{"level":2,"title":"效果演示","slug":"效果演示","link":"#效果演示","children":[]}],"git":{"createdTime":1756997745000,"updatedTime":1758460961000,"contributors":[{"name":"zhouxzh","username":"zhouxzh","email":"zhouxzh@gdut.edu.cn","commits":1,"url":"https://github.com/zhouxzh"},{"name":"Xianzhong Zhou","username":"Xianzhong Zhou","email":"zhouxzh@gdut.edu.cn","commits":1,"url":"https://github.com/Xianzhong Zhou"}]},"readingTime":{"minutes":4.04,"words":1212},"filePathRelative":"experiment/case2.md","localizedDate":"2025年9月4日"}');export{d as comp,o as data};
