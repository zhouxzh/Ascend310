import{_ as l}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as t,d as e,o as a}from"./app-qOQMBkXC.js";const s={};function n(d,i){return a(),t("div",null,i[0]||(i[0]=[e(`<h2 id="章节总览" tabindex="-1"><a class="header-anchor" href="#章节总览"><span>章节总览</span></a></h2><p>本章聚焦“定位 → 解释 → 改善”闭环：从性能分析模型、Profiling 工具、瓶颈模式分类、布局与精度策略、内存与并行调度、到自定义算子开发与验证标准，提供工程可落地方法。目标是让读者具备：A) 定量证明问题；B) 选择低风险优化策略；C) 保证功能与性能回归一致性。</p><h2 id="性能拆解与衡量框架" tabindex="-1"><a class="header-anchor" href="#性能拆解与衡量框架"><span>性能拆解与衡量框架</span></a></h2><p>总时延公式：<code>T_total = T_pre + T_h2d + T_infer + T_d2h + T_post + T_idle</code>。 吞吐上限受制于 <code>max(T_component)</code>；需收集：</p><ul><li>平均/分位数 (p50/p95)；</li><li>波动系数 CV=std/mean（&gt;0.15 需进一步剖析）；</li><li>稳定性：长跑 1h 是否存在漂移 (内存泄漏或热降频)。 对比优化前后必须保留固定随机种子和数据集，消除噪声。</li></ul><h2 id="profiling-工具与时间线解读" tabindex="-1"><a class="header-anchor" href="#profiling-工具与时间线解读"><span>Profiling 工具与时间线解读</span></a></h2><p>关键观测元素：</p><table><thead><tr><th>轨迹</th><th>意义</th><th>异常信号</th></tr></thead><tbody><tr><td>Stream Timeline</td><td>内核调度顺序</td><td>大量空洞 gap</td></tr><tr><td>MemCopy</td><td>H2D/D2H 开销</td><td>频繁小块拷贝</td></tr><tr><td>Task Kernel</td><td>算子执行</td><td>个别算子异常拖长</td></tr><tr><td>Sync/Wait</td><td>Host 等待</td><td>Wait 占比高</td></tr></tbody></table><p>使用策略：</p><ol><li>先全量 Profile → 定位热点范围；</li><li>二次局部 Profile（过滤特定算子类型）；</li><li>导出 JSON → 自动解析器归档：算子耗时 TOPK，Copy 占比，Idle 时间。</li></ol><h2 id="瓶颈模式与处置策略矩阵" tabindex="-1"><a class="header-anchor" href="#瓶颈模式与处置策略矩阵"><span>瓶颈模式与处置策略矩阵</span></a></h2><table><thead><tr><th>模式</th><th>识别特征</th><th>定量指标</th><th>处置优先级</th><th>策略</th></tr></thead><tbody><tr><td>调度空洞</td><td>Timeline gap 多</td><td>Idle &gt; 10%</td><td>高</td><td>合并小算子 / 预加载数据</td></tr><tr><td>访存受限</td><td>算子耗时与内存带宽正相关</td><td>算子内核利用率低</td><td>中</td><td>Layout 变换 / Tile 分块</td></tr><tr><td>H2D 瓶颈</td><td>MemCopy 比例高</td><td>H2D&gt;20%</td><td>高</td><td>合并/异步/Pin/AIPP 下沉</td></tr><tr><td>后处理拖慢</td><td>Post&gt;25%</td><td>NMS/Decode 长</td><td>中</td><td>并行化 / Device 化</td></tr><tr><td>量化退化</td><td>INT8 未获收益</td><td>时延差&lt;10%</td><td>低</td><td>重新校准/混合精度</td></tr><tr><td>单 Stream 阻塞</td><td>单流串行</td><td>Stream=1</td><td>中</td><td>多流/流水线</td></tr></tbody></table><p>优先处理“结构性收益”&gt;“微优化”，避免局部手工 hack 影响可维护性。</p><h2 id="layout-内存访问优化" tabindex="-1"><a class="header-anchor" href="#layout-内存访问优化"><span>Layout / 内存访问优化</span></a></h2><p>常见格式：NCHW（框架常用）、NHWC（部分算子优化）、NC1HWC0（硬件友好对齐），转换策略：在数据首次落地时转换一次；若前后模型不同布局，以中间标准布局连接，减少重复重排。 对齐：通道/宽高按 16/32 边界对齐可提升访存一致性；小通道 (&lt;16) 可考虑 <code>--enable_small_channel</code> 以加载优化内核。 缓存复用：多模型共享中间 Buffer（需尺寸与 dtype 一致），通过分配表管理生命周期。</p><h2 id="精度与性能的层级折衷" tabindex="-1"><a class="header-anchor" href="#精度与性能的层级折衷"><span>精度与性能的层级折衷</span></a></h2><table><thead><tr><th>精度层级</th><th>描述</th><th>性能收益</th><th>风险</th></tr></thead><tbody><tr><td>FP32</td><td>基准</td><td>-</td><td>内存带宽/算力高</td></tr><tr><td>FP16</td><td>半精度</td><td>1.2~1.6x</td><td>累积误差</td></tr><tr><td>INT8 对称</td><td>量化整型</td><td>1.5~2.2x</td><td>量化噪声</td></tr><tr><td>混合精度</td><td>局部高精度</td><td>中等</td><td>实现复杂</td></tr></tbody></table><p>量化流程要点：</p><ol><li>收集代表性校准集（覆盖光照/尺度/类别分布）；</li><li>校准统计（MinMax / KL）；</li><li>评估 Top1/Top5 差异、关键指标差异（mAP/F1）。 误差定位：Dump 中间张量（FP32 vs INT8）→ 层级误差分布 → 定位失真层（常见：激活饱和/尺度不均衡）。</li></ol><h2 id="内存管理专题" tabindex="-1"><a class="header-anchor" href="#内存管理专题"><span>内存管理专题</span></a></h2><p>策略：</p><ol><li>长期 Buffer：模型 I/O、常量 Workspace；</li><li>短期 Buffer：Batch 临时中间；</li><li>建立内存池（按 size class 分类 1KB/4KB/16KB/64KB/大块），分配 → 归还；</li><li>避免频繁 <code>aclrtMalloc/Free</code>：使用池化接口封装；</li><li>监控：每 60s 记录一次池使用率与系统剩余内存，突增后回收未引用对象；</li><li>大对象对齐：按 512B/4KB 对齐减少碎片。</li></ol><h2 id="并行与流水线" tabindex="-1"><a class="header-anchor" href="#并行与流水线"><span>并行与流水线</span></a></h2><p>多 Stream：将独立算子或多模型分离到不同 Stream 并行调度；注意 Host 侧同步点过多会抵消收益。Pipeline：Pre → Infer → Post 分线程队列，目标是 In-Flight 帧数达到平衡（过多增加延迟，过少利用率低）。 自适应调度：定期评估每阶段平均耗时，动态调整线程池大小（PID 控制思想）。</p><h2 id="自定义算子开发与评估" tabindex="-1"><a class="header-anchor" href="#自定义算子开发与评估"><span>自定义算子开发与评估</span></a></h2><p>决策条件：</p><table><thead><tr><th>条件</th><th>必须满足至少一项</th></tr></thead><tbody><tr><td>复合算子频繁出现</td><td>合并降低访存</td></tr><tr><td>内置实现回退 Host</td><td>存在高额拷贝</td></tr><tr><td>内核模式不适配输入规模</td><td>小尺寸性能差</td></tr></tbody></table><p>流程：需求分析 → JSON 定义(<code>op_type</code>, attr, inputs/outputs) → Kernel C++ 模板 (向量化 / Tile) → 编译注册 → ATC 识别 → 功能单测（随机张量对比）→ 性能对比（3 次 Warmup + 50 次统计）。 评估表：</p><table><thead><tr><th>版本</th><th>输入规模</th><th>平均耗时(us)</th><th>P95(us)</th><th>访存次数</th><th>速度提升</th><th>备注</th></tr></thead></table><h2 id="优化案例-add-relu-融合" tabindex="-1"><a class="header-anchor" href="#优化案例-add-relu-融合"><span>优化案例：Add + ReLU 融合</span></a></h2><p>原始：Add → ReLU 两个算子各自读写内存； 融合：单 Kernel 计算 <code>out = relu(a+b)</code>：减少一次读写； 收益估算：内存带宽主导场景中延迟≈(T_add + T_relu - 重叠)，实际提升 10~25%。 验证：随机输入 100 次 → 检查数值一致（允许 1e-6 FP16 差异）→ Benchmark 对比。</p><h2 id="性能报告与回归模板" tabindex="-1"><a class="header-anchor" href="#性能报告与回归模板"><span>性能报告与回归模板</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>{</span></span>
<span class="line"><span>	&quot;commit&quot;: &quot;&lt;git-sha&gt;&quot;,</span></span>
<span class="line"><span>	&quot;model&quot;: &quot;resnet50_fp16&quot;,</span></span>
<span class="line"><span>	&quot;batch&quot;: 1,</span></span>
<span class="line"><span>	&quot;avg_latency_ms&quot;: 5.87,</span></span>
<span class="line"><span>	&quot;p95_latency_ms&quot;: 6.24,</span></span>
<span class="line"><span>	&quot;throughput_fps&quot;: 170.3,</span></span>
<span class="line"><span>	&quot;h2d_ms_ratio&quot;: 0.11,</span></span>
<span class="line"><span>	&quot;post_ms_ratio&quot;: 0.05,</span></span>
<span class="line"><span>	&quot;memory_peak_mb&quot;: 486,</span></span>
<span class="line"><span>	&quot;temperature_c_range&quot;: &quot;54-58&quot;,</span></span>
<span class="line"><span>	&quot;profiling_date&quot;: &quot;2025-09-04T10:21:00Z&quot;</span></span>
<span class="line"><span>}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>自动化：CI 中若 <code>avg_latency_ms</code> 高于基线 5% → 标红注释。</p><h2 id="章节小结" tabindex="-1"><a class="header-anchor" href="#章节小结"><span>章节小结</span></a></h2><p>性能优化不等于盲调：应以数据驱动 + 分层定位为前提，先解决架构级与内存/拷贝问题，再考虑算子级微调与自定义算子开发。量化收益需伴随精度风险评估，内存与并行策略需要可观测支撑。</p><h2 id="实践任务" tabindex="-1"><a class="header-anchor" href="#实践任务"><span>实践任务</span></a></h2><ol><li>对一个部署模型收集 Profiling JSON，输出前 5 算子耗时与占比表。</li><li>实现 H2D 合并：将 3 个连续小拷贝合并为单次，比较平均时延改善。</li><li>尝试 INT8 量化：输出精度与性能对比（Top1/Latency/FPS）。</li><li>编写一个 Add+ReLU 融合算子伪代码 + 预期性能提升估算。</li><li>生成基线性能报告，并设定 CI 回归阈值策略文本说明。</li></ol><h2 id="昇腾310b自定义算子开发全流程" tabindex="-1"><a class="header-anchor" href="#昇腾310b自定义算子开发全流程"><span>昇腾310B自定义算子开发全流程</span></a></h2><p>本节面向 Ascend 310B 推理场景，给出“什么时候需要自定义算子、用什么方法开发、如何编译注册、怎样验证与上线”的系统指引。读完后，你应能独立完成一个简单自定义算子的端到端落地。</p><h3 id="开发概述" tabindex="-1"><a class="header-anchor" href="#开发概述"><span>开发概述</span></a></h3><ul><li>目标：当模型中存在“内置算子不支持/性能欠佳/需要业务特化融合”的场景，通过自定义算子（Custom Op）补齐功能或获得确定性性能收益。</li><li>实现形态： <ul><li>AI Core（TBE/TE/TIK，运行于 NPU 核心，适合数值密集型向量/矩阵计算）。</li><li>AICPU（C++/CPU 实现，在 Host/AICPU 执行，适合控制流或少量数据处理，注意 H2D/D2H 开销）。</li></ul></li><li>产物：算子描述（op info/proto）、算子实现（AI Core: Python 实现并编译为内核；AICPU: C++ so）、注册与打包（放入 OPP 路径），以及 ATC 与运行时可识别的元数据。</li><li>适配 310B：选择 <code>soc_version=Ascend310B</code>，优先 FP16 数据通路；对齐 NC1HWC0 等硬件友好布局；小通道/小尺寸注意 tile 策略。</li></ul><h3 id="开发的理论基础" tabindex="-1"><a class="header-anchor" href="#开发的理论基础"><span>开发的理论基础</span></a></h3><ol><li>硬件/内存模型（简要）： <ul><li>GM(Global Memory)：大容量全局显存，带宽高、时延高；</li><li>UB(Unified Buffer)：片上高速缓冲，容量有限，需 tile 分块搬运；</li><li>Vector/Scalar 单元：提供 vadd/vmul/vmax 等向量指令，需保证数据对齐（通常以 16/32 对齐）。</li><li>DMA：GM 与 UB 之间的数据搬运，批量大块优于频繁小块。</li></ul></li><li>计算表达与调度： <ul><li>TE（Tensor Expression）：描述计算公式与算子图（compute）；</li><li>Schedule：描述分块(tilling)、并行、缓存、向量化等执行计划；</li><li>TIK DSL：更接近硬件指令级的编程接口，适合精细控制。</li></ul></li><li>算子契约（Operator Contract）： <ul><li>输入/输出张量的 shape、dtype、format（如 NCHW/NC1HWC0）、属性（attr）；</li><li>广播/对齐规则、边界行为（溢出/饱和/舍入）、精度策略（FP16/FP32 混合）。</li></ul></li><li>形状推断与动态 shape： <ul><li>ATC 需要根据 op 描述完成 shape infer；</li><li>动态尺寸需在实现中处理 tile 策略切换并保证 UB 不溢出。</li></ul></li></ol><h3 id="开发流程-ai-core-为例" tabindex="-1"><a class="header-anchor" href="#开发流程-ai-core-为例"><span>开发流程（AI Core 为例）</span></a></h3><p>以下流程以一个“Add+ReLU 融合”示例说明，读者可据此扩展到实际业务算子。</p><ol><li>环境准备</li></ol><ul><li>确保 CANN/Toolkit 已安装，能使用 <code>atc</code>、Profiling 等工具；</li><li>设置环境变量： <ul><li><code>ASCEND_INSTALL_PATH</code> 指向 Toolkit 根；</li><li><code>ASCEND_OPP_PATH</code> 指向 OPP 包路径（custom 算子将被放置于此）；</li><li><code>soc_version=Ascend310B</code>（ATC/编译时指定）。</li></ul></li></ul><ol start="2"><li>定义算子信息（op info/proto）</li></ol><ul><li>指定：<code>op_type</code>、inputs/outputs 名称、dtype/format 组合、属性列表、融合类型等；</li><li>作用： <ul><li>供 ATC 做图解析、形状推断与算子选择；</li><li>供运行时校验输入输出与 kernel 适配。</li></ul></li></ul><ol start="3"><li>编写算子实现（TE/TBE）</li></ol><ul><li>计算表达：<div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 伪代码：y = relu(x1 + x2)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> te.lang.cce </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tbe</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> te </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tvm</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> add_relu_compute</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">x1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> x2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">		y </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tbe.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">vadd</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x1, x2)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">		z </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> tbe.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">vmaxs</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(y, tvm.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">const</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, x1.dtype))</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">		return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> z</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li>调度策略（示例要点）： <ul><li>选择合适的 tile 以满足 UB 容量；</li><li>将连续内存访问向量化，减少非对齐访问；</li><li>尽量合并搬运，减少 GM&lt;-&gt;UB 往返；</li><li>小尺寸场景避免过度拆分导致调度开销占比过高。</li></ul></li></ul><ol start="4"><li>编译与注册</li></ol><ul><li>使用官方提供的 TBE 编译入口生成内核与元数据（具体命令因版本而异，遵循已安装 Toolkit 的说明）；</li><li>将生成的实现文件/元数据放入 <code>ASCEND_OPP_PATH</code> 下的 custom 目录（如 <code>op_impl/custom/ai_core/tbe</code>、<code>op_proto/custom</code>）。</li></ul><ol start="5"><li>与 ATC 集成</li></ol><ul><li>在模型转换时指定 <code>--soc_version=Ascend310B</code>；</li><li>确保 ATC 能从 <code>ASCEND_OPP_PATH</code> 读取到你的 op 描述与实现信息；</li><li>若需要限制实现选择，可使用 <code>--op_select_implmode</code> 配合算子实现指示。</li></ul><ol start="6"><li>运行时部署与加载</li></ol><ul><li>运行环境中需要包含同样的 OPP 目录（含 custom 实现）；</li><li>应用进程启动时配置环境变量，使 Runtime 能定位自定义算子实现；</li><li>按常规 ACL 流程加载 OM 并执行推理。</li></ul><ol start="7"><li>验证与度量</li></ol><ul><li>功能正确性：与参考实现（NumPy/ONNXRuntime）对齐，随机多组张量比较（均值绝对误差、相对误差、边界样本）。</li><li>性能评估：Warmup 3 次 + 采样 50 次，输出 avg/p95/FPS；对比内置算子或未融合版本；</li><li>资源占用：Profiling 检查 MemCopy 占比、Kernel 占比、Idle；</li><li>兼容性：不同 shape/dtype/format 组合覆盖测试。</li></ul><ol start="8"><li>文档与产物归档</li></ol><ul><li>输出 <code>op_contract.yaml</code>（IO/Attr/格式/边界规则）；</li><li>输出 <code>benchmark.json</code>（avg/p95、对比基线、硬件/版本信息）；</li><li>产物目录：<code>op_pkg/&lt;op_type&gt;/&lt;version&gt;/{op_proto, op_impl, tests, docs}</code>。</li></ul><h3 id="aicpu-路线-可选" tabindex="-1"><a class="header-anchor" href="#aicpu-路线-可选"><span>AICPU 路线（可选）</span></a></h3><ul><li>适用：控制流、轻量数据处理或暂不需在 NPU 上运行的功能性算子；</li><li>实现：C/C++ 编写，遵循 AICPU 接口，注册到相应目录生成动态库；</li><li>注意：Host 执行会引入 H2D/D2H；若在性能关键路径，优先 AI Core 版本。</li></ul><h3 id="常见问题与排错" tabindex="-1"><a class="header-anchor" href="#常见问题与排错"><span>常见问题与排错</span></a></h3><ul><li>ATC 提示 Unsupported Op：检查 op info 是否被正确放置且生效；确认 <code>soc_version</code> 与路径；</li><li>运行时 Fallback：确认实现 dtype/format 与模型一致；必要时扩充 <code>dtype_format</code> 组合；</li><li>性能未达预期：增大 tile、减少小块 DMA、合并计算、检查是否出现额外 layout 转换；</li><li>精度差异：检查饱和/舍入策略、对齐与广播规则、数据范围（FP16 溢出）。</li></ul><h3 id="本章小结" tabindex="-1"><a class="header-anchor" href="#本章小结"><span>本章小结</span></a></h3><p>自定义算子是 310B 场景下“功能补齐与性能确定性”的关键手段。核心抓手包括：明确契约（IO/格式/属性）、用 TE/TIK 描述计算并设计合理调度、放在 OPP 中正确注册、生效于 ATC 与运行时、用可度量的基线进行功能/性能回归。建议从“融合与复合算子”起步，优先选择计算密集、访存友好的目标，循序渐进积累模板与脚手架，以降低维护成本。</p>`,68)]))}const o=l(s,[["render",n],["__file","chapter5.html.vue"]]),p=JSON.parse('{"path":"/book/chapter5.html","title":"第5讲：性能与算子优化初阶","lang":"zh-cn","frontmatter":{"title":"第5讲：性能与算子优化初阶","author":["周贤中"],"date":"2025-09-04T00:00:00.000Z","subject":"Markdown","keywords":["性能优化","Profiling","自定义算子","内存调优","Layout","量化"],"lang":"zh-cn"},"headers":[{"level":2,"title":"章节总览","slug":"章节总览","link":"#章节总览","children":[]},{"level":2,"title":"性能拆解与衡量框架","slug":"性能拆解与衡量框架","link":"#性能拆解与衡量框架","children":[]},{"level":2,"title":"Profiling 工具与时间线解读","slug":"profiling-工具与时间线解读","link":"#profiling-工具与时间线解读","children":[]},{"level":2,"title":"瓶颈模式与处置策略矩阵","slug":"瓶颈模式与处置策略矩阵","link":"#瓶颈模式与处置策略矩阵","children":[]},{"level":2,"title":"Layout / 内存访问优化","slug":"layout-内存访问优化","link":"#layout-内存访问优化","children":[]},{"level":2,"title":"精度与性能的层级折衷","slug":"精度与性能的层级折衷","link":"#精度与性能的层级折衷","children":[]},{"level":2,"title":"内存管理专题","slug":"内存管理专题","link":"#内存管理专题","children":[]},{"level":2,"title":"并行与流水线","slug":"并行与流水线","link":"#并行与流水线","children":[]},{"level":2,"title":"自定义算子开发与评估","slug":"自定义算子开发与评估","link":"#自定义算子开发与评估","children":[]},{"level":2,"title":"优化案例：Add + ReLU 融合","slug":"优化案例-add-relu-融合","link":"#优化案例-add-relu-融合","children":[]},{"level":2,"title":"性能报告与回归模板","slug":"性能报告与回归模板","link":"#性能报告与回归模板","children":[]},{"level":2,"title":"章节小结","slug":"章节小结","link":"#章节小结","children":[]},{"level":2,"title":"实践任务","slug":"实践任务","link":"#实践任务","children":[]},{"level":2,"title":"昇腾310B自定义算子开发全流程","slug":"昇腾310b自定义算子开发全流程","link":"#昇腾310b自定义算子开发全流程","children":[{"level":3,"title":"开发概述","slug":"开发概述","link":"#开发概述","children":[]},{"level":3,"title":"开发的理论基础","slug":"开发的理论基础","link":"#开发的理论基础","children":[]},{"level":3,"title":"开发流程（AI Core 为例）","slug":"开发流程-ai-core-为例","link":"#开发流程-ai-core-为例","children":[]},{"level":3,"title":"AICPU 路线（可选）","slug":"aicpu-路线-可选","link":"#aicpu-路线-可选","children":[]},{"level":3,"title":"常见问题与排错","slug":"常见问题与排错","link":"#常见问题与排错","children":[]},{"level":3,"title":"本章小结","slug":"本章小结","link":"#本章小结","children":[]}]}],"git":{"createdTime":1752741756000,"updatedTime":1758457965000,"contributors":[{"name":"zhouxzh","username":"zhouxzh","email":"zhouxzh@gdut.edu.cn","commits":2,"url":"https://github.com/zhouxzh"},{"name":"idsefa","username":"idsefa","email":"hhc92611@gmail.com","commits":1,"url":"https://github.com/idsefa"},{"name":"Xianzhong Zhou","username":"Xianzhong Zhou","email":"zhouxzh@gdut.edu.cn","commits":2,"url":"https://github.com/Xianzhong Zhou"}]},"readingTime":{"minutes":9.91,"words":2974},"filePathRelative":"book/chapter5.md","localizedDate":"2025年9月4日"}');export{o as comp,p as data};
